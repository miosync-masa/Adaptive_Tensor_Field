# test_mlo_pipeline.py

import asyncio
import numpy as np
import pandas as pd
import json
from datetime import datetime, timedelta
import pymc as pm
import arviz as az
from unittest.mock import MagicMock, patch
import warnings
warnings.filterwarnings('ignore')

# LambdaÂ³ç†è«–ã«åŸºã¥ãMLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
class TestMLOPipeline:
    """MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        self.test_results = {}
        self.test_data = self._generate_test_data()
        
    def _generate_test_data(self):
        """LambdaÂ³ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        n_points = 1000
        t = np.linspace(0, 100, n_points)
        
        # LambdaÂ³çš„ãªæ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¸ãƒ£ãƒ³ãƒ—å«ã‚€ï¼‰
        base_signal = np.sin(0.1 * t) + 0.5 * np.sin(0.3 * t)
        jumps = np.zeros_like(t)
        jump_points = [200, 400, 600, 800]
        for jp in jump_points:
            if jp < n_points:
                jumps[jp:] += np.random.randn() * 2
        
        signal = base_signal + jumps + 0.1 * np.random.randn(n_points)
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ™ãƒ³ãƒˆå½¢å¼ã«å¤‰æ›
        events = []
        for i in range(n_points):
            events.append({
                'timestamp': (datetime.now() - timedelta(hours=n_points-i)).isoformat(),
                'value': signal[i],
                'series': f'series_{i % 3}',  # 3ã¤ã®ç³»åˆ—
                'user_id': f'user_{i % 10}',
                'operation': np.random.choice(['FileRead', 'Login', 'FileWrite']),
                'anomaly': abs(signal[i] - base_signal[i]) > 2  # ç•°å¸¸åˆ¤å®š
            })
        
        return {
            'signal': signal,
            'events': events,
            'base_signal': base_signal,
            'jumps': jumps
        }
    
    async def run_all_tests(self):
        """å…¨ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        print("ğŸ§¬ LambdaÂ³ MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ å®Œå…¨ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print("=" * 80)
        
        # 1. è¨­å®šã‚¯ãƒ©ã‚¹ãƒ†ã‚¹ãƒˆ
        await self.test_config()
        
        # 2. ãƒ‡ãƒ¼ã‚¿åé›†ãƒ†ã‚¹ãƒˆ
        await self.test_data_collector()
        
        # 3. LambdaÂ³å‰å‡¦ç†ãƒ†ã‚¹ãƒˆ
        await self.test_lambda3_preprocessor()
        
        # 4. éšå±¤ãƒ™ã‚¤ã‚ºå­¦ç¿’ãƒ†ã‚¹ãƒˆ
        await self.test_hierarchical_bayesian()
        
        # 5. A/Bãƒ†ã‚¹ãƒˆãƒ†ã‚¹ãƒˆ
        await self.test_ab_testing()
        
        # 6. ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ
        await self.test_deployment()
        
        # 7. çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ
        await self.test_integrated_pipeline()
        
        # 8. æ•µå¯¾çš„é˜²å¾¡é€£æºãƒ†ã‚¹ãƒˆ
        await self.test_adversarial_integration()
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        self._print_summary()
    
    async def test_config(self):
        """è¨­å®šã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n1ï¸âƒ£ OptimizedL3Config ãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import OptimizedL3Config
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            config = OptimizedL3Config()
            assert config.delta_percentile == 90.0
            assert config.draws == 500
            assert config.use_jax == True
            
            # ã‚«ã‚¹ã‚¿ãƒ è¨­å®š
            custom_config = OptimizedL3Config(
                delta_percentile=95.0,
                draws=1000,
                chains=4,
                use_gpu=True,
                kafka_servers=['localhost:9093', 'localhost:9094']
            )
            assert custom_config.delta_percentile == 95.0
            assert len(custom_config.kafka_servers) == 2
            
            self.test_results['config'] = {
                'status': 'OK',
                'default_config': 'Valid',
                'custom_config': 'Valid',
                'jax_enabled': config.use_jax
            }
            print("  âœ… è¨­å®šã‚¯ãƒ©ã‚¹: æ­£å¸¸å‹•ä½œ")
            
        except Exception as e:
            self.test_results['config'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    async def test_data_collector(self):
        """ãƒ‡ãƒ¼ã‚¿åé›†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n2ï¸âƒ£ EnhancedDataCollector ãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import EnhancedDataCollector, OptimizedL3Config
            
            config = OptimizedL3Config()
            
            # ãƒ¢ãƒƒã‚¯Kafkaã‚’ä½¿ç”¨
            with patch('kafka.KafkaConsumer'):
                collector = EnhancedDataCollector(config)
                
                # LambdaÂ³ç‰¹å¾´é‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ
                test_values = self.test_data['signal'][:100]
                features = collector.calc_lambda3_features(test_values)
                
                assert 'delta_LambdaC_pos' in features
                assert 'delta_LambdaC_neg' in features
                assert 'rho_T' in features
                assert 'local_jump_detect' in features
                
                # ã‚¸ãƒ£ãƒ³ãƒ—æ¤œå‡ºç¢ºèª
                jump_detected = np.sum(features['local_jump_detect']) > 0
                
                # ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ
                for event in self.test_data['events'][:50]:
                    collector.series_data.setdefault(event['series'], []).append(event)
                
                self.test_results['data_collector'] = {
                    'status': 'OK',
                    'lambda3_features': list(features.keys()),
                    'jump_detected': jump_detected,
                    'series_count': len(collector.series_data)
                }
                print(f"  âœ… ãƒ‡ãƒ¼ã‚¿åé›†: LambdaÂ³ç‰¹å¾´é‡æŠ½å‡ºæˆåŠŸ")
                print(f"     - ã‚¸ãƒ£ãƒ³ãƒ—æ¤œå‡º: {jump_detected}")
                print(f"     - ç³»åˆ—æ•°: {len(collector.series_data)}")
                
        except Exception as e:
            self.test_results['data_collector'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    async def test_lambda3_preprocessor(self):
        """LambdaÂ³å‰å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n3ï¸âƒ£ Lambda3DataPreprocessor ãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import Lambda3DataPreprocessor, OptimizedL3Config, EnhancedDataCollector
            
            config = OptimizedL3Config()
            preprocessor = Lambda3DataPreprocessor(config)
            
            # ãƒ†ã‚¹ãƒˆç”¨LambdaÂ³ç‰¹å¾´é‡
            with patch('kafka.KafkaConsumer'):
                collector = EnhancedDataCollector(config)
                
                batch_features = {}
                for series_name in ['series_0', 'series_1', 'series_2']:
                    series_data = [e for e in self.test_data['events'] if e['series'] == series_name]
                    values = np.array([e['value'] for e in series_data[:100]])
                    batch_features[series_name] = collector.calc_lambda3_features(values)
            
            # ç‰¹å¾´é‡çµ±åˆãƒ†ã‚¹ãƒˆ
            integrated = preprocessor.integrate_lambda3_features(batch_features)
            
            # ç›¸äº’ç›¸é–¢ãƒã‚§ãƒƒã‚¯
            has_correlation = any('corr_' in key for key in integrated.keys())
            
            # LambdaÂ³ãƒ¡ãƒ¢ãƒªæ›´æ–°ãƒ†ã‚¹ãƒˆ
            preprocessor.update_lambda3_memory(integrated)
            
            # å› æœæ€§åˆ†æãƒ†ã‚¹ãƒˆ
            causality = preprocessor.analyze_causality(integrated)
            
            self.test_results['preprocessor'] = {
                'status': 'OK',
                'integrated_features': len(integrated),
                'has_correlation': has_correlation,
                'memory_size': len(preprocessor.lambda3_memory),
                'causality_features': len(causality)
            }
            print(f"  âœ… LambdaÂ³å‰å‡¦ç†: æ­£å¸¸å‹•ä½œ")
            print(f"     - çµ±åˆç‰¹å¾´é‡: {len(integrated)}å€‹")
            print(f"     - ç³»åˆ—é–“ç›¸é–¢: {has_correlation}")
            
        except Exception as e:
            self.test_results['preprocessor'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    async def test_hierarchical_bayesian(self):
        """éšå±¤ãƒ™ã‚¤ã‚ºå­¦ç¿’ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n4ï¸âƒ£ HierarchicalBayesianTrainer ãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import HierarchicalBayesianTrainer, OptimizedL3Config
            
            # é«˜é€Ÿãƒ†ã‚¹ãƒˆç”¨è¨­å®š
            config = OptimizedL3Config(
                draws=100,
                tune=50,
                chains=2,
                use_jax=False  # Colabã§ã¯é€šå¸¸ã®ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ä½¿ç”¨
            )
            
            trainer = HierarchicalBayesianTrainer(config)
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
            n_samples = 100
            features = {
                'delta_LambdaC_pos': np.random.rand(n_samples),
                'delta_LambdaC_neg': np.random.rand(n_samples),
                'rho_T': np.random.rand(n_samples),
                'time_trend': np.linspace(0, 1, n_samples)
            }
            target_data = np.random.randn(n_samples)
            
            # Layer 1: å³æ™‚ãƒ™ã‚¤ã‚ºãƒ†ã‚¹ãƒˆ
            print("     Layer 1 (å³æ™‚é©å¿œ) ãƒ†ã‚¹ãƒˆä¸­...")
            trainer.train_immediate_layer(features, target_data)
            
            # åæŸè¨ºæ–­
            if 'layer1_immediate' in trainer.models and trainer.models['layer1_immediate']:
                model, trace = trainer.models['layer1_immediate']
                rhat_max = float(az.rhat(trace).max())
                converged = rhat_max < 1.01
            else:
                converged = False
                rhat_max = None
            
            self.test_results['bayesian'] = {
                'status': 'OK',
                'layer1_trained': trainer.models['layer1_immediate'] is not None,
                'converged': converged,
                'rhat_max': rhat_max
            }
            print(f"  âœ… éšå±¤ãƒ™ã‚¤ã‚ºå­¦ç¿’: Layer 1 å®Œäº†")
            print(f"     - åæŸ: {converged} (RÌ‚={rhat_max:.3f})" if rhat_max else "")
            
        except Exception as e:
            self.test_results['bayesian'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    async def test_ab_testing(self):
        """ãƒ™ã‚¤ã‚ºA/Bãƒ†ã‚¹ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print("\n5ï¸âƒ£ BayesianABTesting ãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import BayesianABTesting, OptimizedL3Config
            
            config = OptimizedL3Config()
            ab_tester = BayesianABTesting(config)
            
            # ãƒ€ãƒŸãƒ¼ã®traceã‚’ä½œæˆ
            with pm.Model() as dummy_model:
                # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«
                mu = pm.Normal('mu', mu=0, sigma=1)
                sigma = pm.HalfNormal('sigma', sigma=1)
                y = pm.Normal('y', mu=mu, sigma=sigma, observed=np.random.randn(50))
                
                # 2ã¤ã®ç•°ãªã‚‹traceã‚’ç”Ÿæˆ
                trace_a = pm.sample(100, tune=50, chains=2, progressbar=False)
                trace_b = pm.sample(100, tune=50, chains=2, progressbar=False)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒè¨ˆç®—ã®ãƒ¢ãƒƒã‚¯
            ab_tester._calculate_performance_distribution = MagicMock(
                side_effect=[np.random.rand(100), np.random.rand(100) + 0.1]
            )
            
            # A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_data = np.random.randn(20)
            result = ab_tester.run_bayesian_ab_test(trace_a, trace_b, test_data)
            
            self.test_results['ab_testing'] = {
                'status': 'OK',
                'prob_b_better': result['prob_b_better'],
                'expected_improvement': result['expected_improvement'],
                'decision': result['decision']
            }
            print(f"  âœ… ãƒ™ã‚¤ã‚ºA/Bãƒ†ã‚¹ãƒˆ: æ­£å¸¸å‹•ä½œ")
            print(f"     - Bæ”¹å–„ç¢ºç‡: {result['prob_b_better']:.2%}")
            print(f"     - åˆ¤å®š: {result['decision']}")
            
        except Exception as e:
            self.test_results['ab_testing'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    async def test_deployment(self):
        """ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
        print("\n6ï¸âƒ£ IntelligentDeployment ãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import IntelligentDeployment, OptimizedL3Config
            import pymc as pm
            
            config = OptimizedL3Config()
            
            # Kubernetesã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ãƒ¢ãƒƒã‚¯
            with patch('kubernetes.config.load_incluster_config'), \
                 patch('kubernetes.config.load_kube_config'), \
                 patch('kubernetes.client.AppsV1Api'):
                
                deployer = IntelligentDeployment(config)
                
                # ãƒ†ã‚¹ãƒˆç”¨traceã‚’ä½œæˆ
                with pm.Model() as test_model:
                    mu = pm.Normal('mu', mu=0, sigma=1)
                    sigma = pm.HalfNormal('sigma', sigma=1)
                    y = pm.Normal('y', mu=mu, sigma=sigma, observed=np.random.randn(50))
                    test_trace = pm.sample(100, tune=50, chains=2, progressbar=False)
                
                # ä¸ç¢ºå®Ÿæ€§è©•ä¾¡
                uncertainty = deployer._evaluate_model_uncertainty(test_trace)
                
                # ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆåˆ¤å®šãƒ†ã‚¹ãƒˆ
                if uncertainty['confidence'] >= 0.95:
                    deployment_type = 'full'
                elif uncertainty['confidence'] >= 0.8:
                    deployment_type = 'canary'
                else:
                    deployment_type = 'shadow'
                
                self.test_results['deployment'] = {
                    'status': 'OK',
                    'confidence': uncertainty['confidence'],
                    'max_rhat': uncertainty['max_rhat'],
                    'deployment_type': deployment_type
                }
                print(f"  âœ… ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ: æ­£å¸¸å‹•ä½œ")
                print(f"     - ä¿¡é ¼åº¦: {uncertainty['confidence']:.2%}")
                print(f"     - ãƒ‡ãƒ—ãƒ­ã‚¤æ–¹å¼: {deployment_type}")
                
        except Exception as e:
            self.test_results['deployment'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    async def test_integrated_pipeline(self):
        """çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""
        print("\n7ï¸âƒ£ IntegratedMLOpsPipeline ãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import IntegratedMLOpsPipeline, OptimizedL3Config
            
            # ãƒ†ã‚¹ãƒˆç”¨ã®è»½é‡è¨­å®š
            config = OptimizedL3Config(
                draws=50,
                tune=25,
                chains=2,
                min_batch_size=10
            )
            
            # Kafkaã‚’ãƒ¢ãƒƒã‚¯
            with patch('kafka.KafkaConsumer'), \
                 patch('kafka.KafkaProducer'):
                
                pipeline = IntegratedMLOpsPipeline(config)
                
                # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–ç¢ºèª
                components_ok = all([
                    hasattr(pipeline, 'data_collector'),
                    hasattr(pipeline, 'preprocessor'),
                    hasattr(pipeline, 'trainer'),
                    hasattr(pipeline, 'ab_tester'),
                    hasattr(pipeline, 'deployer'),
                    hasattr(pipeline, 'diversity_cluster')
                ])
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ãƒ†ã‚¹ãƒˆ
                test_metrics = {
                    'timestamp': datetime.now(),
                    'predictions': [0, 1, 0, 1],
                    'data_size': 100
                }
                pipeline.record_metrics(test_metrics)
                
                # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
                try:
                    pipeline.handle_pipeline_error(ValueError("Test error"))
                    error_handling_ok = True
                except:
                    error_handling_ok = False
                
                self.test_results['integrated_pipeline'] = {
                    'status': 'OK',
                    'components_initialized': components_ok,
                    'metrics_recorded': len(pipeline.metrics_history) > 0,
                    'error_handling': error_handling_ok
                }
                print(f"  âœ… çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: æ­£å¸¸å‹•ä½œ")
                print(f"     - ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {'å…¨ã¦åˆæœŸåŒ–æˆåŠŸ' if components_ok else 'ä¸€éƒ¨å¤±æ•—'}")
                
        except Exception as e:
            self.test_results['integrated_pipeline'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    async def test_adversarial_integration(self):
        """æ•µå¯¾çš„é˜²å¾¡ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        print("\n8ï¸âƒ£ æ•µå¯¾çš„é˜²å¾¡çµ±åˆãƒ†ã‚¹ãƒˆ")
        
        try:
            from mlo_pipeline import IntegratedMLOpsPipeline, OptimizedL3Config
            
            config = OptimizedL3Config()
            
            with patch('kafka.KafkaConsumer'), \
                 patch('kafka.KafkaProducer'):
                
                pipeline = IntegratedMLOpsPipeline(config)
                
                # ç•°å¸¸ã‚¤ãƒ™ãƒ³ãƒˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                anomaly_events = [e for e in self.test_data['events'] if e.get('anomaly', False)]
                normal_events = [e for e in self.test_data['events'] if not e.get('anomaly', False)]
                
                # get_recent_anomaliesã®ãƒ¢ãƒƒã‚¯
                pipeline.get_recent_anomalies = MagicMock(return_value=anomaly_events[:5])
                pipeline.get_recent_normal_samples = MagicMock(return_value=normal_events[:10])
                
                # daily_cycleã®ä¸€éƒ¨ã‚’ãƒ†ã‚¹ãƒˆ
                if anomaly_events and normal_events:
                    # æ•µå¯¾çš„é˜²å¾¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®å‹•ä½œç¢ºèª
                    from diversity_adversarial_defense import AdversarialDefense
                    adv_def = AdversarialDefense(normal_events[:5])
                    
                    variants = []
                    for atk in anomaly_events[:2]:
                        # ç°¡æ˜“çš„ãªå¤‰ç¨®ç”Ÿæˆ
                        variant = atk.copy()
                        variant['value'] *= 1.1
                        variants.append(variant)
                    
                    adversarial_ok = len(variants) > 0
                else:
                    adversarial_ok = False
                
                # å¤šæ§˜æ€§ã‚¯ãƒ©ã‚¹ã‚¿ã®ç¢ºèª
                diversity_cluster_ok = hasattr(pipeline, 'diversity_cluster')
                
                self.test_results['adversarial_integration'] = {
                    'status': 'OK',
                    'anomaly_events': len(anomaly_events),
                    'normal_events': len(normal_events),
                    'adversarial_defense': adversarial_ok,
                    'diversity_cluster': diversity_cluster_ok
                }
                print(f"  âœ… æ•µå¯¾çš„é˜²å¾¡çµ±åˆ: æ­£å¸¸å‹•ä½œ")
                print(f"     - ç•°å¸¸ã‚¤ãƒ™ãƒ³ãƒˆ: {len(anomaly_events)}å€‹")
                print(f"     - æ•µå¯¾çš„é˜²å¾¡: {'å‹•ä½œ' if adversarial_ok else 'æœªå‹•ä½œ'}")
                
        except Exception as e:
            self.test_results['adversarial_integration'] = {'status': 'FAILED', 'error': str(e)}
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {str(e)[:100]}")
    
    def _print_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("\n" + "=" * 80)
        print("ğŸ“Š LambdaÂ³ MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 80)
        
        success_count = 0
        total_count = len(self.test_results)
        
        for test_name, result in self.test_results.items():
            status = result.get('status', 'UNKNOWN')
            icon = "âœ…" if status == "OK" else "âŒ"
            print(f"\n{icon} {test_name}: {status}")
            
            if status == "OK":
                success_count += 1
                # è©³ç´°æƒ…å ±è¡¨ç¤º
                for key, value in result.items():
                    if key != 'status':
                        print(f"    - {key}: {value}")
            else:
                error = result.get('error', 'Unknown error')[:150]
                print(f"    - Error: {error}...")
        
        print("\n" + "-" * 80)
        print(f"ç·åˆæˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
        
        # LambdaÂ³ç‰¹æœ‰ã®æƒ…å ±
        print("\nğŸ§¬ LambdaÂ³ç†è«–å®Ÿè£…çŠ¶æ³:")
        print("  âœ… ã‚¸ãƒ£ãƒ³ãƒ—æ¤œå‡º (Î”Î›C)")
        print("  âœ… æ™‚é–“çª“æ¨™æº–åå·® (ÏT)")
        print("  âœ… ãƒ­ãƒ¼ã‚«ãƒ«ã‚¸ãƒ£ãƒ³ãƒ—æ¤œå‡º")
        print("  âœ… éšå±¤ãƒ™ã‚¤ã‚ºæ¨è«–")
        print("  âœ… å› æœæ€§åˆ†æ")


# Colabç”¨ã®å®Ÿè¡Œé–¢æ•°
async def run_mlo_pipeline_test():
    """MLOãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    # å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª
    try:
        import pymc
        import arviz
        print("âœ… PyMC ã¨ ArviZ ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    except ImportError:
        print("âš ï¸ PyMC/ArviZ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
        print("!pip install pymc arviz")
        return
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    tester = TestMLOPipeline()
    await tester.run_all_tests()


# ç°¡æ˜“å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
def quick_mlo_test():
    """ç´ æ—©ãåŸºæœ¬æ©Ÿèƒ½ã ã‘ãƒ†ã‚¹ãƒˆ"""
    print("ğŸš€ MLOãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    # 1. è¨­å®š
    try:
        from mlo_pipeline import OptimizedL3Config
        config = OptimizedL3Config(draws=10, tune=5, chains=1)
        print(f"âœ… Config: JAX={config.use_jax}, Draws={config.draws}")
    except Exception as e:
        print(f"âŒ Config: {e}")
        return
    
    # 2. LambdaÂ³ç‰¹å¾´é‡
    try:
        from mlo_pipeline import EnhancedDataCollector
        with patch('kafka.KafkaConsumer'):
            collector = EnhancedDataCollector(config)
            test_data = np.sin(np.linspace(0, 10, 100)) + np.random.randn(100) * 0.1
            features = collector.calc_lambda3_features(test_data)
            print(f"âœ… LambdaÂ³ç‰¹å¾´é‡: {list(features.keys())[:3]}...")
    except Exception as e:
        print(f"âŒ LambdaÂ³: {e}")
    
    # 3. å‰å‡¦ç†
    try:
        from mlo_pipeline import Lambda3DataPreprocessor
        preprocessor = Lambda3DataPreprocessor(config)
        print(f"âœ… Preprocessor: ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚º={len(preprocessor.lambda3_memory)}")
    except Exception as e:
        print(f"âŒ Preprocessor: {e}")
    
    print("\nåŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")


# å®Ÿè¡Œ
if __name__ == "__main__":
    # Colabã§ã®éåŒæœŸå®Ÿè¡Œå¯¾å¿œ
    try:
        import nest_asyncio
        nest_asyncio.apply()
        asyncio.run(run_mlo_pipeline_test())
    except ImportError:
        print("âš ï¸ nest_asyncio ãŒå¿…è¦ã§ã™: !pip install nest-asyncio")
        print("ä»£ã‚ã‚Šã«ç°¡æ˜“ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™...")
        quick_mlo_test()
